\documentclass[11pt,openany]{article}

\input{grad-math-preamble}
\input{tcolorbox}
\input{theorem}
\input{tikz}
\input{grad-math-commands}


\usepackage{mathtools}


\DeclareMathOperator{\sgn}{sgn}

\renewcommand{\vec}[1]{\mathbf{#1}}
\renewcommand{\Re}{\operatorname*{Re}}
\renewcommand{\Im}{\operatorname*{Im}}
\newcommand{\Mat}{\operatorname{Mat}}

\newcommand{\Sym}{\mathrm{Sym}}

%\newcommand{\F}{\mathbb{F}}
%\newcommand{\R}{\mathbb{R}}
%\newcommand{\C}{\mathbb{C}}
%\newcommand{\Span}{\operatorname{span}}
%\newcommand{\Mat}{\operatorname{Mat}}
\newcommand{\tr}{\operatorname{tr}}
\renewcommand{\d}{\mathrm{d}} % For the exterior derivative 'd'
\newcommand{\pderiv}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\spderiv}[3]{\frac{\partial^2 #1}{\partial #2\partial #3}}
\newcommand{\GL}{\operatorname{GL}}
\newcommand{\restrict}[2]{{#1}\!\mid_{#2}}



%\newcommand{\basis}{def}

\setstretch{1.25}

\begin{document}
\pagenumbering{arabic}
\begin{center}
	\huge\textbf{Linear Algebra IV}\\
	\vspace{0.5em}
	\large{Ji Yonghyeon,\; Bae Dongsung}\\
	\vspace{0.5em}
	\normalsize{\today}\\
\end{center}

\noindent 
We cover the following topics in this note.
\begin{itemize}
	\item Eigenvectors and Diagonalization.
	\begin{itemize}
		\item[*] Hessian Matrix
		\item[*] Differential Equation
	\end{itemize}
	\item TBA.
\end{itemize}
\hrule\vspace{12pt}
%\tableofcontents
\vfill

\newpage
\begin{notation}
	\;
	\begin{itemize}
		\item Let \(\F\) is a field (typical cases: \(\R\) or \(\C\)).
		\item Let \(V\) is a finite-dimensional \(\F\)-vector space.
		\item Let \(T:V\to V\) is a linear operator.
	\end{itemize}
\end{notation}
\begin{observation}[Choosing a basis to simplify a linear map]
Let $\basis=\set{\textbf{v}_1,\dots,\textbf{v}_n}$ be a basis of $V$ such that $[T]_{\basis}$ is a diagonal matrix: 
\[
[T]_{\basis}=[T]_{\basis}^{\basis}=\begin{bmatrix}
	{\color{blue}d_1} & 0 & \cdots & 0\\
	0 & {\color{blue}d_1} & \cdots & 0 \\
	\vdots & \vdots & \ddots & \vdots \\
	0 & 0 & \cdots & {\color{blue}d_n} \\
\end{bmatrix}_{n\times n},\quad\ie,\quad T(\textbf{v}_i)=d_i\textbf{v}_i\;\text{with}\; 1\leq i\leq n.
\]
Then $T$ may be very complicated, but with respect to $[T]_{\basis}$ it looks nice. 
%%(``$T$ acts by scalars on the coordinate directions''). 
\end{observation}

\medskip

\defbox[Eigenvector \& Eigenvalue]{\begin{definition*}
	Let $T:V\to V$ be $\F$-linear. A nonzero vector $\textbf{v}\in V\setminus\set{\textbf{0}}$ is an \emph{eigenvector} of $T$ if there exists $\lambda\in\F$ such that
	\[
	T(\textbf{v})=\lambda \textbf{v}\in V.
	\]
	The scalar $\lambda$ is called the \textbf{eigenvalue} corresponding to $\textbf{v}$.
\end{definition*}}
\begin{remark}
	If \(\textbf{v}\neq 0\) and \(T(\textbf{v})=\lambda \textbf{v}\), then the one-dimensional subspace \(\F \textbf{v}\) satisfying
	\[
	\fullfunction{T|_{\F \textbf{v}}}{\F \textbf{v}}{\F \textbf{v}}{c\textbf{v}}{\lambda(c\textbf{v})}\qquad(\because T(c\textbf{v})=cT(\textbf{v})=c\lambda \textbf{v}=\lambda(c\textbf{v})),
	\]
	Equivalently, the restriction \( \restrict{T}{\F \textbf{v}}:\F \textbf{v}\to \F \textbf{v}\) acts as scalar multiplication by \(\lambda\).
\end{remark}

\medskip

\newpage
\begin{remark}
	Let $T:V\to V$ be $\F$-linear. Let a subspace $W\le V$ satisfy 	\[
	T[W]\subseteq W\qquad(\iff\forall\,\textbf{w}\in W,\; T(\textbf{w})\in W).
	\]
	\begin{enumerate}
		\item The restriction map
		\[
		T|_{W}:W\to W,\qquad \textbf{w}\mapsto T(\textbf{w})
		\]
		is a well-defined linear operator on $W$.
		\item If $\dim V<\infty$ and $\mathcal{B}=(\textbf{w}_1,\dots,\textbf{w}_k,\textbf{v}_{k+1},\dots,\textbf{v}_n)$
		is a basis of $V$ such that $(\textbf{w}_1,\dots,\textbf{w}_k)$ is a basis of $W$, then
		\[
		[T]_{\mathcal{B}}=
		\begin{pmatrix}
			A & *\\
			{\color{red}0} & B
		\end{pmatrix},
		\]
		where $A$ represents $T|_{W}$ and $B$ represents the induced map on $V/W$.
	\end{enumerate}
\begin{center}
	\includegraphics[scale=1.25]{grad-math-tikz/kds3-linear-algebra-4-tikz1.pdf}
\end{center}
\end{remark}

\medskip

\defbox[Diagonalizability of Linear Operator]{
\begin{definition*}
	We say $T:V\to V$ is \emph{diagonalizable} if $\exists$ a basis $\basis$ of $V$ such that 
%	the matrix of $T$ 
%	with respect to that basis 
	$[T]_\basis$ is diagonal.
\end{definition*}}
\begin{remark}
$T$ is diagonalizable if and only if $V$ has a basis consisting of eigenvectors of $T$. 

\noindent
A diagonal matrix \[
\begin{bmatrix}
	d_1 & \cdots & 0 \\
	\vdots &\ddots & \vdots \\
	0 & \cdots & d_n
\end{bmatrix}
\] acts by scaling each basis vector $\textbf{v}_i$ \textit{independently}, and ``scaling a nonzero vector'' is the eigenvector condition $T(\textbf{v}_i)=d_i\textbf{v}_i$.
\end{remark}


\newpage
\begin{example}[Hessian; Quadratic form diagonalization]
Note that \begin{itemize}
	\item Single variable Taylor series: \begin{align*}
	f(x)
	&= f(p) + \frac{1}{1!}f'(p)(x-p) + \frac{1}{2!}f''(p)(x-p)^2 + \cdots= \sum_{k=0}^{n}\frac{f^{(k)}(p)}{k!}(x-p)^k + R.
	\end{align*}
	\item Two variables Taylor series: \begin{align*}
	f(x,y) &= f(p,q)
+ \frac{1}{1!}\,f_x(p,q)(x-p) + \frac{1}{1!}\,f_y(p,q)(y-q) \\
& \quad\;\; + \frac{1}{2!}\,f_{xx}(p,q)(x-p)^2 + \frac{1}{1!}\,f_{xy}(p,q)(x-p)(y-q)
+ \frac{1}{2!}\,f_{yy}(p,q)(y-q)^2 + \cdots
	\end{align*}
Let
\[
X=\begin{bmatrix}x-p \\ y-q\end{bmatrix},\qquad \nabla f=\begin{bmatrix}
\pderiv{}{x}f\\ \pderiv{}{y}f
\end{bmatrix},\qquad
H=\begin{bmatrix} f_{xx} & f_{xy}\\ f_{yx} & f_{yy}\end{bmatrix}.
\] Then \begin{align*}
	f(x,y)&=\mathcolorbox{-blue}{f(p,q)} + \mathcolorbox{-red}{\frac{1}{1!} 
	\begin{bmatrix}
		f_x & f_y
	\end{bmatrix}\begin{bmatrix}x-p\\ y-q\end{bmatrix}}+\mathcolorbox{-green}{
	\frac{1}{2!}\begin{bmatrix}
		x-p & y-q
	\end{bmatrix}\begin{bmatrix} f_{xx} & f_{xy}\\ f_{yx} & f_{yy}\end{bmatrix}
	\begin{bmatrix}
		x-p \\ y-q
	\end{bmatrix}}+R\\
	&= \mathcolorbox{-blue}{f(p,q)} + \mathcolorbox{-red}{\frac{1}{1!}\,\nabla f^{\,T}X} + \mathcolorbox{-green}{\frac{1}{2!}\,X^{T}HX} + R.
\end{align*}
%\newpage\noindent
Consider $f(x,y)=2x^2+2xy+2y^2$. Then $H=\begin{bmatrix}f_{xx}&f_{xy}\\ f_{yx}& f_{yy}\end{bmatrix}=\begin{bmatrix}4&2\\2&4\end{bmatrix}.$
Let
\[
X=\begin{bmatrix}x\\y\end{bmatrix}
\quad\Rightarrow\quad
f=X^{T}HX.
\]
Eigenpairs:
\[
\lambda_1=6 \ \Rightarrow\ \frac{1}{\sqrt{2}}\begin{bmatrix}1\\1\end{bmatrix},
\qquad
\lambda_2=2 \ \Rightarrow\ \frac{1}{\sqrt{2}}\begin{bmatrix}1\\-1\end{bmatrix}.
\]
So
\[
Q=\frac{1}{\sqrt{2}}
\begin{bmatrix}
	1&1\\
	1&-1
\end{bmatrix},
\qquad
D=\operatorname{diag}(\lambda_1,\lambda_2)=\operatorname{diag}(6,2),
\qquad
H=Q^{T}DQ.
\]
Hence
\[
f=X^THX=X^{T}(Q^{T}DQ)X=(QX)^{T}D(QX).
\]
Let $
QX:=V=\begin{bmatrix}u\\v\end{bmatrix}$ then \[
u=\frac{x+y}{\sqrt{2}},\qquad \ v=\frac{x-y}{\sqrt{2}}.
\]
Then
\[
f=V^{T}DV
=\begin{bmatrix}u\ \ v\end{bmatrix}
\begin{bmatrix}6&0\\0&2\end{bmatrix}
\begin{bmatrix}u\\v\end{bmatrix}
=6u^2+2v^2.
\] Here, intersection term $(xy)$ disappeared.
\end{itemize}
\end{example}

\medskip

%\begin{example}[Differential Equation 1]
%	For the linear system
%	\[
%	\begin{cases}
%		x_1'= a_{11}x_1+a_{12}x_2,\\
%		x_2'= a_{21}x_1+a_{22}x_2.
%	\end{cases}\Rightarrow\begin{bmatrix}
%		x_1'\\ x_2'
%	\end{bmatrix}=\begin{bmatrix}
%	a_{11} & a_{12} \\
%	a_{21} & a_{22}
%\end{bmatrix}
%\begin{bmatrix}
%x_1\\ x_2
%\end{bmatrix}\left(\Leftrightarrow X'=AX\right),
%	\] if \(A=PDP^{-1}\) (diagonalizable), set \(Y=P^{-1}X\). Then \(X=PY\), and
%	\[
%	X'=PY',\qquad AX=A(PY)=(PDP^{-1})PY=PDY,
%	\]
%	so
%	\[
%	PY' = PDY \quad\Rightarrow\quad Y'=DY
%	=\operatorname{diag}(\lambda_1,\lambda_2)\,Y.
%	\]
%%	Thus each component solves
%%	\[
%%	y_i'=\lambda_i y_i
%%	\quad\Rightarrow\quad
%%	y_i=c_i e^{\lambda_i t},
%%	\qquad
%%	x=Py.
%%	\]
%	
%	\newpage
%	\[
%	x' = Ax,
%	\qquad
%	A=\begin{bmatrix}3&1\\1&3\end{bmatrix}.
%	\]
%	\[
%	\lambda=4 \Rightarrow \frac{1}{\sqrt{2}}\begin{bmatrix}1\\1\end{bmatrix},
%	\qquad
%	\lambda=2 \Rightarrow \frac{1}{\sqrt{2}}\begin{bmatrix}1\\-1\end{bmatrix}.
%	\]
%	Define
%	\[
%	u=\frac{x+y}{\sqrt{2}},\qquad v=\frac{x-y}{\sqrt{2}}
%	\quad\Rightarrow\quad
%	x=\frac{u+v}{\sqrt{2}},\ \ y=\frac{u-v}{\sqrt{2}}.
%	\]
%	Then
%	\[
%	\begin{bmatrix}u'\\v'\end{bmatrix}
%	=
%	\operatorname{diag}(4,2)\begin{bmatrix}u\\v\end{bmatrix}
%	=
%	\begin{bmatrix}4u\\2v\end{bmatrix},
%	\]
%	so
%	\[
%	u=c_1 e^{4t},\qquad v=c_2 e^{2t}.
%	\]
%	With initial data \(x(0)=x_0,\ y(0)=y_0\), \begin{align*}
%	x(t)=\frac12\Big((x_0+y_0)e^{4t}+(x_0-y_0)e^{2t}\Big),\\
%	y(t)=\frac12\Big((x_0+y_0)e^{4t}-(x_0-y_0)e^{2t}\Big).
%	\end{align*}
%\end{example}
%
%\begin{example}[Differential Equation 2] 
%	Consider $x' = Ax$ with \[
%	A=\begin{bmatrix}2&1\\0&3\end{bmatrix},
%	\qquad
%	x=\begin{bmatrix}x_1\\x_2\end{bmatrix},
%	\qquad
%	x_1(0)=a,\ x_2(0)=b.
%	\] Then
%	\[
%	\lambda_1=2 \Rightarrow \begin{bmatrix}1\\0\end{bmatrix},
%	\qquad
%	\lambda_2=3 \Rightarrow \begin{bmatrix}1\\1\end{bmatrix}.
%	\]
%	So
%	\[
%	A=PDP^{-1}=\begin{bmatrix}1&1\\0&1\end{bmatrix}
%	\operatorname{diag}(2,3)\begin{bmatrix}1&-1\\0&1\end{bmatrix}.
%	\]
%	Let \(y=P^{-1}x\). Then
%	\[
%	y'=Dy
%	\quad\Rightarrow\quad
%	\begin{cases}
%		y_1=c_1 e^{2t},\\
%		y_2=c_2 e^{3t}.
%	\end{cases}
%	\]
%	Also
%	\[
%	\begin{cases}
%		y_1=x_1-x_2,\\
%		y_2=x_2
%	\end{cases}
%	\quad\Rightarrow\quad
%	\begin{cases}	
%		x_1=y_1+y_2,\quad x_2=y_2.
%	\end{cases}
%	\]
%	With \(c_1=a-b,\ c_2=b\), $\begin{cases}
%		x_1(t)=(a-b)e^{2t}+be^{3t}, \\
%		x_2(t)=be^{3t}.
%	\end{cases}$
%\end{example}

%For
%\[
%x' = Ax,
%\qquad \text{and } A=PDP^{-1}\ \text{일 때,}
%\]
%let \(y=P^{-1}x\) 으로 치환하면 \(x=Py\) 이고,
%\[
%Py' = PDP^{-1}x = PDy
%\quad\Rightarrow\quad
%y'=Dy=\operatorname{diag}(\lambda_1,\dots,\lambda_n)\,y.
%\]
%Thus
%\[
%y_i'=\lambda_i y_i
%\quad\Rightarrow\quad
%y_i=c_i e^{\lambda_i t},
%\qquad
%x=Py.
%\]
%
%\subsection*{Example 1}
%\[
%x' = Ax,
%\qquad
%A=\begin{bmatrix}3&1\\1&3\end{bmatrix}.
%\]
%\[
%\lambda=4 \Rightarrow \frac{1}{\sqrt{2}}\begin{bmatrix}1\\1\end{bmatrix},
%\qquad
%\lambda=2 \Rightarrow \frac{1}{\sqrt{2}}\begin{bmatrix}1\\-1\end{bmatrix}.
%\]
%Let
%\[
%u=\frac{x+y}{\sqrt{2}},\qquad v=\frac{x-y}{\sqrt{2}}
%\quad\Rightarrow\quad
%x=\frac{u+v}{\sqrt{2}},\ \ y=\frac{u-v}{\sqrt{2}}.
%\]
%Then
%\[
%\begin{bmatrix}u'\\v'\end{bmatrix}
%=
%\operatorname{diag}(4,2)\begin{bmatrix}u\\v\end{bmatrix}
%=
%\begin{bmatrix}4u\\2v\end{bmatrix},
%\]
%so
%\[
%u=c_1 e^{4t},\qquad v=c_2 e^{2t}.
%\]
%With initial data \(x(0)=x_0,\ y(0)=y_0\),
%\[
%x(t)=\frac12\Big((x_0+y_0)e^{4t}+(x_0-y_0)e^{2t}\Big),
%\]
%\[
%y(t)=\frac12\Big((x_0+y_0)e^{4t}-(x_0-y_0)e^{2t}\Big).
%\]
%
%\subsection*{Example 2}
%\[
%x' = Ax,
%\qquad
%A=\begin{bmatrix}2&1\\0&3\end{bmatrix},
%\qquad
%x=\begin{bmatrix}x_1\\x_2\end{bmatrix},
%\qquad
%x_1(0)=a,\ x_2(0)=b.
%\]
%\[
%\lambda_1=2 \Rightarrow \begin{bmatrix}1\\0\end{bmatrix},
%\qquad
%\lambda_2=3 \Rightarrow \begin{bmatrix}1\\1\end{bmatrix}.
%\]
%So
%\[
%P=\begin{bmatrix}1&1\\0&1\end{bmatrix},
%\qquad
%D=\operatorname{diag}(2,3),
%\qquad
%A=PDP^{-1},
%\qquad
%P^{-1}=\begin{bmatrix}1&-1\\0&1\end{bmatrix}.
%\]
%Let \(y=P^{-1}x\), then \(x=Py\) and
%\[
%y'=Dy
%\quad\Rightarrow\quad
%y_1=c_1 e^{2t},\qquad y_2=c_2 e^{3t}.
%\]
%Also
%\[
%y_1=x_1-x_2,\qquad y_2=x_2
%\quad\Rightarrow\quad
%x_1=y_1+y_2,\quad x_2=y_2.
%\]
%With \(c_1=a-b,\ c_2=b\),
%\[
%x_1(t)=(a-b)e^{2t}+be^{3t},
%\qquad
%x_2(t)=be^{3t}.
%\]

\medskip

\vspace{10pt}
%\vfill

\begin{note}
Let \(A\in \Mat_n(\F)\). The associated linear map \(L_A:\F^n\to\F^n\) is given by \(L_A(\textbf{x})=A\textbf{x}\).
\end{note}
\defbox[Diagonalizability of Matrix]{\begin{definition}
A matrix \(A\in \Mat_n(\F)\) is \emph{diagonalizable over \(\F\)} if \(\exists P\in \GL_n(\F)\) and a diagonal matrix \(D\) such that
\[
P^{-1}AP=D.
\]
\end{definition}}

\probox[Eigenbasis and Similarity]{
\begin{proposition}
Let \(A\in\Mat_n(\F)\).
\begin{enumerate}[(i)]
	\item If \(\mathcal{B}=\set{\textbf{v}_1,\dots,\textbf{v}_n}\) is a basis of \(\F^n\) consisting of eigenvectors of \(A\), and \(P=[\textbf{v}_1\ \cdots\ \textbf{v}_n]\), then \(P^{-1}AP\) is diagonal with \(P\in\GL_n(\F)\).
	\item Conversely, if \(P^{-1}AP=D\) is diagonal, then the columns of \(P\) form an eigenbasis of \(A\) (with eigenvalues given by the diagonal entries of \(D\)).
\end{enumerate}
\end{proposition}}


\newpage
\defbox[Characteristic polynomial]{\begin{definition}
	For \(A\in\Mat_n(\F)\), the \textbf{characteristic polynomial} of \(A\) is
	\[
	\chi_A(\lambda)\coloneqq \det(A-\lambda I_n)\in \F[\lambda].
	\]
\end{definition}}

\probox[Eigenvalues are roots]{\begin{proposition}
	A scalar \(\lambda\in\F\) is an eigenvalue of \(A\) if and only if \(\chi_A(\lambda)=0\).
\end{proposition}}


\newpage
\begin{observation}[Characteristic polynomial in $2\times 2$] 
Let $A=\begin{bmatrix} a&b\\ c&d \end{bmatrix}\in\Mat_{2}(\F)$. Then 
\begin{center}
\begin{minipage}{.495\textwidth}
\begin{align*}
	\det(A-{\color{blue}\lambda} I_2)&=
	\det\begin{bmatrix} a-{\color{blue}\lambda}&b\\ c&d-{\color{blue}\lambda} \end{bmatrix}\\
	&=(a-{\color{blue}\lambda})(d-{\color{blue}\lambda})-bc\\
	&=ad-(a+d){\color{blue}\lambda}+{\color{blue}\lambda}^2-bc\\
	&={\color{blue}\lambda}^2-(a+d){\color{blue}\lambda}+(ad-bc)\\
	&={\color{blue}\lambda}^2-\tr(A){\color{blue}\lambda}+\det(A).
\end{align*}
\end{minipage}\hfill\begin{minipage}{.495\textwidth}\centering
\includegraphics[scale=1]{grad-math-tikz/kds3-linear-algebra-4-tikz2.pdf}
\end{minipage}
\end{center}
\end{observation}

\medskip

\begin{observation}[Characteristic polynomial in $3\times 3$]
	Let $
	A=\begin{bmatrix}
		a & b & c\\
		d & e & f\\
		g & h & i
	\end{bmatrix}\in \Mat_{3}(\F).$ Then \begin{align*}
	\det(A-\lambda I_3)
	&=
	\det\begin{bmatrix}
		a-{\color{blue}\lambda}&b&c\\
		d&e-{\color{blue}\lambda}&f\\
		g&h&i-{\color{blue}\lambda}
	\end{bmatrix}
	=
	(a-{\color{blue}\lambda})\det\begin{bmatrix}
		e-{\color{blue}\lambda}&f\\
		h&i-{\color{blue}\lambda}
	\end{bmatrix}
	-b\det\begin{bmatrix}
		d&f\\
		g&i-{\color{blue}\lambda}
	\end{bmatrix}
	+c\det\begin{bmatrix}
		d&e-{\color{blue}\lambda}\\
		g&h
	\end{bmatrix}\\
	&=(a-{\color{blue}\lambda})\bigl((e-{\color{blue}\lambda})(i-{\color{blue}\lambda})-fh\bigr)
	-b\bigl(d(i-{\color{blue}\lambda})-fg\bigr)
	+c\bigl(dh-ge+g{\color{blue}\lambda}\bigr)\\
	&=(a-{\color{blue}\lambda})\bigl(ei-(e+i){\color{blue}\lambda}+{\color{blue}\lambda}^2-fh\bigr)
	-b\bigl(di-d{\color{blue}\lambda}-fg\bigr)
	+c\bigl(dh-ge+g{\color{blue}\lambda}\bigr)\\
	&=\bigl(aei-a(e+i){\color{blue}\lambda}+a{\color{blue}\lambda}^2-afh\bigr)-
	\bigl(ei{\color{blue}\lambda}-(e+i){\color{blue}\lambda}^2+{\color{blue}\lambda}^3-fh{\color{blue}\lambda}\bigr)
	\\
	&\hspace{10pt}-\bigl(bdi-bd{\color{blue}\lambda}-bfg\bigr)
	+\bigl(cdh-cge+cg{\color{blue}\lambda}\bigr)\\
	&=-{\color{blue}\lambda}^3+(a+e+i){\color{blue}\lambda}^2-(ae+ai+ei-fh-bd-cg){\color{blue}\lambda}+(aei-afh-bdi-bfg+cdh-cge)\\
	&=-{\color{blue}\lambda}^3+\tr(A){\color{blue}\lambda}^2-\left(\det\!\begin{bmatrix}a&b\\ d&e\end{bmatrix}
	+\det\!\begin{bmatrix}a&c\\ g&i\end{bmatrix}
	+\det\!\begin{bmatrix}e&f\\ h&i\end{bmatrix}\right){\color{blue}\lambda}+\det(A).
	\end{align*}
\begin{center}
\includegraphics[scale=1]{grad-math-tikz/kds3-linear-algebra-4-tikz3.pdf}
\end{center}
\end{observation}

\newpage
\begin{remark}
	Over an algebraic closure, if $\lambda_1,\lambda_2,\lambda_3$ are the eigenvalues of $A$ (with algebraic multiplicity), then
	\begin{align*}
		\chi_A(\lambda)&=-(\lambda-\lambda_1)(\lambda-\lambda_2)(\lambda-\lambda_3) \\
		&=-(\lambda^2-\lambda(\lambda_1+\lambda_2)+\lambda_1\lambda_2)(\lambda-\lambda_3) \\
		&=-(\lambda^3-\lambda^2(\lambda_1+\lambda_2+\lambda_3)+\lambda(\lambda_1\lambda_2+\lambda_2\lambda_3+\lambda_3\lambda_1)+\lambda_1\lambda_2\lambda_3)
	\end{align*}
	so $\tr(A)=\lambda_1+\lambda_2+\lambda_3$ and $\det(A)=\lambda_1\lambda_2\lambda_3$.
\end{remark}

\thmbox[Characteristic polynomial: Trace and Determinant as coefficients]{
\begin{theorem}
Let $A\in\Mat_n(\F)$. Define the characteristic polynomial \[
\chi_A(\lambda)\coloneqq \det(A-\lambda I_n)\in \F[\lambda].
\]
Then $\chi_A(\lambda)$ is a polynomial of degree $n$ and can be written uniquely as
\[
\chi_A(\lambda)=\sum_{i=0}^{n}c_i\lambda^i=c_n \lambda^n+c_{n-1}\lambda^{n-1}+\cdots+c_1 \lambda+c_0.
\]
The coefficients satisfy:
\begin{enumerate}
	\item $c_n=(-1)^n$.
	\item $c_{n-1}=(-1)^{n-1}\tr(A)$.
	\item $c_0=\det(A)$.
\end{enumerate}
Equivalently,
\[
\chi_A(\lambda)=(-1)^n \lambda^n+(-1)^{n-1}(\tr A)\,\lambda^{n-1}+\cdots+\det(A).
\]
\end{theorem}}
\begin{proof}
We use the mathematical induction on $n$.	
	
\medskip
\noindent\textbf{(Base case $n=1$)}\;
If $A=[a]$, then
\[
\chi_A(\lambda)=\det[a-\lambda]=a-\lambda=(-1)^1\lambda^1+(-1)^0 a.
\]
Thus $c_1=-1=(-1)^1$, $c_0=a=\det(A)$, and $c_0=(-1)^0\tr(A)$ is consistent since $\tr(A)=a$.

\medskip
\noindent\textbf{(Induction step)}
Assume the theorem holds for all $(n-1)\times(n-1)$ matrices over $\F$.
Let $A=(a_{ij})\in\Mat_n(\F)$ and set
\[
M(\lambda)\coloneqq A-\lambda I_n.
\]
Expand $\det(M(\lambda))$ by Laplace expansion along the first row:
\begin{equation}\label{eq:laplace-first-row}
	\chi_A(\lambda)=\det(M(\lambda))
	=\sum_{j=1}^n (-1)^{1+j}\,(a_{1j}-\lambda\delta_{1j})\,\det\bigl(M(\lambda)_{1j}\bigr),
\end{equation}
where $M(\lambda)_{1j}$ denotes the $(n-1)\times(n-1)$ matrix obtained by deleting row $1$ and column $j$.

\medskip
\noindent\textbf{Claim 1: $c_n=(-1)^n$ and $\deg\chi_A=n$.}
Observe that $\det(M(\lambda)_{1j})$ is a polynomial in $\lambda$ of degree at most $n-1$.
Moreover:
\begin{itemize}
	\item If $j\neq 1$, then $(a_{11}-\lambda)$ does not appear, and the prefactor is $a_{1j}$ (independent of $\lambda$).
	Hence the corresponding summand in \eqref{eq:laplace-first-row} has degree $\le n-1$.
	\item If $j=1$, then the prefactor is $(a_{11}-\lambda)$, so the degree of that summand is
	$1+\deg\det(M(\lambda)_{11})$.
\end{itemize}
Therefore the coefficient of $\lambda^n$ can only come from the $j=1$ summand:
\[
(a_{11}-\lambda)\det(M(\lambda)_{11}).
\]

Now identify $M(\lambda)_{11}$ explicitly. Deleting row $1$ and column $1$ removes the first diagonal position,
so
\[
M(\lambda)_{11} = A_{11}-\lambda I_{n-1},
\]
where $A_{11}$ is the $(n-1)\times(n-1)$ minor of $A$ (delete row $1$, column $1$).
By the induction hypothesis applied to $A_{11}$,
\[
\det(A_{11}-\lambda I_{n-1}) = (-1)^{n-1}\lambda^{n-1} + \text{(lower degree terms)}.
\]
Multiplying by $(a_{11}-\lambda)$, the $\lambda^n$ term is
\[
(a_{11}-\lambda)\Bigl((-1)^{n-1}\lambda^{n-1}+\cdots\Bigr)
= (-\lambda)\cdot (-1)^{n-1}\lambda^{n-1}+\cdots
= (-1)^n\lambda^n+\cdots.
\]
Hence $c_n=(-1)^n$, and in particular $\deg\chi_A=n$.

\medskip
\noindent\textbf{Claim 2: $c_{n-1}=(-1)^{n-1}\tr(A)$.}
We extract the coefficient of $\lambda^{n-1}$ from \eqref{eq:laplace-first-row}.
Split the sum into the $j=1$ term and the $j\neq 1$ terms.

\smallskip
\noindent\emph{(i) Contribution from $j=1$.}
Write the expansion (by induction hypothesis) for the $(n-1)\times(n-1)$ matrix $A_{11}$:
\[
\det(A_{11}-\lambda I_{n-1})
= (-1)^{n-1}\lambda^{n-1} + (-1)^{n-2}\tr(A_{11})\,\lambda^{n-2}+\cdots.
\]
Then
\begin{align*}
	(a_{11}-\lambda)\det(A_{11}-\lambda I_{n-1})
	&= a_{11}\Bigl((-1)^{n-1}\lambda^{n-1}+\cdots\Bigr)
	-\lambda\Bigl((-1)^{n-1}\lambda^{n-1}+(-1)^{n-2}\tr(A_{11})\lambda^{n-2}+\cdots\Bigr)\\
	&= a_{11}(-1)^{n-1}\lambda^{n-1} \;+\; \underbrace{(-1)^{n-1}(-\lambda)\lambda^{n-1}}_{\text{degree }n}\;+\;
	\Bigl[-(-1)^{n-2}\tr(A_{11})\lambda^{n-1}\Bigr]+\cdots.
\end{align*}
Thus the coefficient of $\lambda^{n-1}$ coming from $j=1$ equals
\[
(-1)^{n-1}a_{11} \;-\; (-1)^{n-2}\tr(A_{11})
= (-1)^{n-1}\bigl(a_{11}+\tr(A_{11})\bigr).
\]

\smallskip
\noindent\emph{(ii) Contribution from $j\neq 1$.}
For $j\neq 1$, the prefactor in \eqref{eq:laplace-first-row} is $a_{1j}$ (degree $0$ in $\lambda$), so
only the $\lambda^{n-1}$ term of $\det(M(\lambda)_{1j})$ could contribute. But $\det(M(\lambda)_{1j})$
is a determinant of size $(n-1)\times(n-1)$ in which the diagonal contains only $(n-2)$ entries of the form $(\cdot-\lambda)$:
indeed, deleting column $j\neq 1$ removes the diagonal position corresponding to index $j$ while deleting row $1$ removes index $1$,
so among indices $\{2,\dots,n\}$ we are missing one diagonal index. Consequently,
\[
\deg \det(M(\lambda)_{1j}) \le n-2 \qquad (j\neq 1),
\]
and therefore the $j\neq 1$ summands contribute nothing to the $\lambda^{n-1}$ coefficient.

\smallskip
Combining (i) and (ii),
\[
c_{n-1}=(-1)^{n-1}\bigl(a_{11}+\tr(A_{11})\bigr).
\]
Finally, since $\tr(A)=a_{11}+\tr(A_{11})$ (the trace is the sum of diagonal entries, and $A_{11}$
contains exactly the remaining diagonal entries $a_{22},\dots,a_{nn}$),
we get
\[
c_{n-1}=(-1)^{n-1}\tr(A).
\]

\medskip
\noindent\textbf{Claim 3: $c_0=\det(A)$.}
Evaluating at $\lambda=0$ gives
\[
c_0=\chi_A(0)=\det(A-0\cdot I_n)=\det(A).
\]
(This step is compatible with induction, but does not require it.)

\medskip
This completes the induction and proves all three coefficient identities.	
	
\newpage
Write $A$ in block form by separating the first row and column:
\[
A=
\begin{pmatrix}
	a_{11} & r\\
	c & B
\end{pmatrix},
\]
where $r\in \Mat_{1\times(n-1)}(\F)$ is the first row with the first entry removed,
$c\in \Mat_{(n-1)\times 1}(\F)$ is the first column with the first entry removed,
and $B\in\Mat_{n-1}(\F)$ is the $(n-1)\times(n-1)$ lower-right block.

Then
\[
A-\lambda I_n=
\begin{pmatrix}
	a_{11}-\lambda & r\\
	c & B-\lambda I_{n-1}
\end{pmatrix}.
\]

\medskip
\noindent\textbf{(1) Degree and leading coefficient.}
Expand $\det(A-\lambda I_n)$ along the first row:
\[
\det(A-\lambda I_n)
=(a_{11}-\lambda)\det(B-\lambda I_{n-1})
+\sum_{j=2}^n (-1)^{1+j}a_{1j}\,\det(M_{1j}(\lambda)),
\]
where $M_{1j}(\lambda)$ is the $(n-1)\times(n-1)$ minor obtained by deleting row $1$ and column $j$.

Key observation (degree-counting in matrix form):
\begin{itemize}
	\item $\det(B-\lambda I_{n-1})$ has degree $n-1$ with leading term $(-1)^{n-1}\lambda^{n-1}$.
	\item For $j\ge 2$, the matrix $M_{1j}(\lambda)$ is obtained from $B-\lambda I_{n-1}$ by deleting
	one of its columns (corresponding to the deleted column $j$). Hence $M_{1j}(\lambda)$ contains at most
	$n-2$ diagonal entries of the form $(\cdot-\lambda)$, so \emph{every} term in $\det(M_{1j}(\lambda))$
	has degree at most $n-2$. Thus $\deg\det(M_{1j}(\lambda))\le n-2$.
\end{itemize}

Therefore the only source of a $\lambda^n$ term is
\[
(a_{11}-\lambda)\det(B-\lambda I_{n-1}),
\]
and its $\lambda^n$ coefficient is
\[
(-\lambda)\cdot\bigl((-1)^{n-1}\lambda^{n-1}\bigr)=(-1)^n\lambda^n.
\]
Hence $c_n=(-1)^n$ and $\deg\chi_A=n$.

\medskip
\noindent\textbf{(2) The $\lambda^{n-1}$ coefficient and the trace.}
From the same expansion, the summation terms with $j\ge 2$ cannot contribute to $\lambda^{n-1}$
because they have degree $\le n-2$. Hence $c_{n-1}$ comes solely from
\[
(a_{11}-\lambda)\det(B-\lambda I_{n-1}).
\]
Write the first two top-degree terms of $\det(B-\lambda I_{n-1})$ in the same convention:
\[
\det(B-\lambda I_{n-1})
= (-1)^{n-1}\lambda^{n-1}+(-1)^{n-2}\tr(B)\,\lambda^{n-2}+\text{(lower powers)}.
\]
(Here we are using the $(n-1)\times(n-1)$ case, i.e.\ induction on size.)

Multiply:
\begin{align*}
	(a_{11}-\lambda)\det(B-\lambda I_{n-1})
	&=a_{11}\Bigl((-1)^{n-1}\lambda^{n-1}+\cdots\Bigr)
	-\lambda\Bigl((-1)^{n-1}\lambda^{n-1}+(-1)^{n-2}\tr(B)\lambda^{n-2}+\cdots\Bigr)\\
	&=\Bigl[(-1)^{n-1}a_{11}-(-1)^{n-2}\tr(B)\Bigr]\lambda^{n-1}
	+\text{(terms of degree $\neq n-1$)}.
\end{align*}
Thus
\[
c_{n-1}=(-1)^{n-1}a_{11}-(-1)^{n-2}\tr(B)=(-1)^{n-1}\bigl(a_{11}+\tr(B)\bigr).
\]
But $\tr(A)=a_{11}+\tr(B)$ (trace is the sum of diagonal entries; $B$ contains $a_{22},\dots,a_{nn}$),
so
\[
c_{n-1}=(-1)^{n-1}\tr(A).
\]

\medskip
\noindent\textbf{(3) Constant term.}
Evaluating at $\lambda=0$ gives
\[
c_0=\chi_A(0)=\det(A-0\cdot I_n)=\det(A).
\]
\end{proof}

\newpage


\vfill
\begin{thebibliography}{9}
	\bibitem{linear_algebra_h}
	수학의 즐거움, Enjoying Math. ``수학 공부, 기초부터 대학원 수학까지, 31. 선형대수학 (h) 고유벡터와 행렬의 대각화 -1'' YouTube Video, 29:46. Published 
	November 06, 2019. URL: \url{https://www.youtube.com/watch?v=RSOxa1rI_Kk}.
%	\bibitem{linear_algebra_i}
%	수학의 즐거움, Enjoying Math. ``수학 공부, 기초부터 대학원 수학까지, 32. 선형대수학 (i) 고유치와 행렬의 대각화 -2'' YouTube Video, 30:21. Published 
%	November 08, 2019. URL: \url{https://www.youtube.com/watch?v=bjEuNw0FnPw}.
%	\bibitem{linear_algebra_j}
%	수학의 즐거움, Enjoying Math. ``수학 공부, 기초부터 대학원 수학까지, 33. 선형대수학 (j) 행렬의 대각화와 고유공간'' YouTube Video, 29:59. Published 
%	November 09, 2019. URL: \url{https://www.youtube.com/watch?v=AlTo9fqlSn8}.
\end{thebibliography}
\end{document}
